{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%history\n"
     ]
    }
   ],
   "source": [
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256,256))\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms)\n",
    "# Create DataLoader for training and testing datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: torch.Size([8, 3, 256, 256])\n",
      "Labels shape: torch.Size([8])\n",
      "horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CIFAR labels to human readable labels\n",
    "CIFAR10_CLASSES = [\n",
    "    'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "data = next(test_iter)\n",
    "images, labels = data\n",
    "\n",
    "# Check the shape of the images and labels\n",
    "print(f'Images shape: {images.shape}')\n",
    "print(f'Labels shape: {labels.shape}')\n",
    "\n",
    "#decode the first image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(2, 2))  # keep this small to avoid blur\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')  # no interpolation\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "print(CIFAR10_CLASSES[labels[0].item()])\n",
    "imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "#create patch of image\n",
    "\n",
    "def splitBatch(images):\n",
    "    B,C,H,W = images.shape\n",
    "    patch_size = 16\n",
    "\n",
    "    y = []\n",
    "\n",
    "    for i in range(H//(patch_size)):\n",
    "        for j in range(W//patch_size):\n",
    "            x = images[:,:,i*patch_size:(i+1)*patch_size,j*patch_size:(j+1)*patch_size]\n",
    "            x = x.reshape(B,-1)\n",
    "            y.append(x)\n",
    "\n",
    "    y = torch.stack(y,dim=1)\n",
    "\n",
    "    return y\n",
    "\n",
    "import  torch.nn.functional as F\n",
    "class MultiHeadAttn(nn.Module):\n",
    "    def __init__(self,num_head=4,embedding_dim=588):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_head = num_head\n",
    "        self.head_dim = embedding_dim//num_head\n",
    "    \n",
    "        self.linear = nn.Linear(embedding_dim,3*embedding_dim)\n",
    "        self.out_proj = nn.Linear(embedding_dim,embedding_dim)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #x-> B,Context_length,embedding_dim\n",
    "        B,C,T = x.shape\n",
    "        kqv = self.linear(x) #B,Context length,3*embedding dim\n",
    "        kqv = kqv.reshape(B,C,3,self.num_head,self.head_dim)\n",
    "        kqv = kqv.permute(2,3,0,1,4)\n",
    "        k,q,v = kqv[0],kqv[1],kqv[2] #head,B,C,T/head\n",
    "        attn = (q@(k.transpose(3,2)))/(self.head_dim)**0.5 #head,B,C,C\n",
    "        attn = F.softmax(attn,dim=-1) # head,B,C,C\n",
    "        y = attn @ v # head,B,C,T/head\n",
    "        y = y.permute(1,2,0,3) #B,C,C,T/Head\n",
    "        y = y.reshape(B,C,-1)\n",
    "        return self.out_proj(y)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,embedding_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(embedding_dim,4*embedding_dim)\n",
    "        self.relu = nn.GELU()\n",
    "        self.linear2 = nn.Linear(4*embedding_dim,embedding_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,num_head=4,embedding_dim=588):\n",
    "        super().__init__()\n",
    "        self.layer_norm_1 = nn.LayerNorm(embedding_dim)\n",
    "        self.mha = MultiHeadAttn(num_head,embedding_dim)\n",
    "        self.layer_norm_2 = nn.LayerNorm(embedding_dim)\n",
    "        self.mlp = MLP(embedding_dim)\n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        residual = x.clone()\n",
    "        x = self.layer_norm_1(x)\n",
    "        x = self.mha(x)\n",
    "        x = x+residual\n",
    "        residual = x.clone()\n",
    "        x = self.layer_norm_2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = x + residual\n",
    "        return x\n",
    "\n",
    "class VIT(nn.Module):\n",
    "    def __init__(self,layer_num = 12,patch_size=14,channels = 3,context_length=196,embedding_dim = 588,num_attn_head = 8,class_size=10):\n",
    "        super(VIT,self).__init__()\n",
    "        self.context_length = context_length\n",
    "        self.LinearProj = nn.Linear(in_features=patch_size*patch_size*channels,out_features=embedding_dim)\n",
    "        self.embedding = nn.Embedding(num_embeddings=1,embedding_dim=embedding_dim)\n",
    "        self.pos_embedding = nn.Embedding(num_embeddings=context_length+1,embedding_dim=embedding_dim)\n",
    "        self.encoder_blocks = nn.ModuleList([Transformer(num_head = num_attn_head,embedding_dim=embedding_dim) for i in range(layer_num)])\n",
    "        self.mlp = MLP(embedding_dim)\n",
    "        self.class_proj = nn.Linear(embedding_dim,10)\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self,image):\n",
    "        #image---> (B,context_length,P*P*3)\n",
    "        B,C,feature_size = image.shape\n",
    "        x = self.LinearProj(image)\n",
    "        cls_token = self.embedding(torch.tensor([0],device='cuda'))\n",
    "        cls_token = cls_token.unsqueeze(0).expand(B, 1, -1)  # [64, 1, 768]\n",
    "        x = torch.cat([cls_token,x],dim=1) \n",
    "        pos = torch.arange(0,self.context_length+1).to(device='cuda')\n",
    "        pos_ = self.pos_embedding(pos)\n",
    "        x = x + self.pos_embedding(pos)  \n",
    "        for enc in self.encoder_blocks:\n",
    "            x = enc(x)\n",
    "        \n",
    "        x = self.mlp(x)\n",
    "\n",
    "        cls_em = self.class_proj(x[:,0])\n",
    "\n",
    "        return cls_em\n",
    "\n",
    "#vit  = VIT(layer_num=8,patch_size=16,channels=3,context_length=256,embedding_dim=768,num_attn_head=8,class_size=10).to('cuda')\n",
    "# optimizer = torch.optim.Adam(params=vit.parameters(),lr = 1e-3)\n",
    "\n",
    "# print(len(train_loader))\n",
    "# print(len(train_dataset))\n",
    "# num_epoch = 3\n",
    "# num_grad_accum=16\n",
    "# total_loss = 0\n",
    "\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader) * num_epoch)  # full schedule over all steps\n",
    "\n",
    "# for epoch in range(num_epoch):\n",
    "#     for i, (images, labels) in enumerate(iter(train_loader)):\n",
    "#         images = images.to('cuda')\n",
    "#         patches = splitBatch(images)\n",
    "#         y = vit(patches)\n",
    "#         labels = labels.to('cuda')\n",
    "#         loss = F.cross_entropy(y,labels)/num_grad_accum\n",
    "#         total_loss+=loss.item()\n",
    "#         loss.backward()\n",
    "#         if(i%num_grad_accum==1):\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "#             scheduler.step()  # step after every optimizer update\n",
    "\n",
    "            \n",
    "#         if(i%num_grad_accum==1):\n",
    "#             print(f\"\\rEpoch {epoch}, Step {i+1}/{len(train_loader)} - Loss: {total_loss:.4f}, Acc: {acc:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\", end='')\n",
    "#             total_loss=0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Step 6240/6250 - Loss: 1.7447, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 6240/6250 - Loss: 1.5245, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 6240/6250 - Loss: 1.7042, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Step 6240/6250 - Loss: 1.6952, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Step 6240/6250 - Loss: 1.3948, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Step 6240/6250 - Loss: 1.5224, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Step 6240/6250 - Loss: 1.5751, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Step 6240/6250 - Loss: 1.3357, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Step 6240/6250 - Loss: 1.4030, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Step 6240/6250 - Loss: 1.3264, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Step 6240/6250 - Loss: 1.3938, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Step 6240/6250 - Loss: 1.3627, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Step 6240/6250 - Loss: 1.2044, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Step 6240/6250 - Loss: 1.0216, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Step 6240/6250 - Loss: 1.0849, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Step 6240/6250 - Loss: 1.3154, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Step 6240/6250 - Loss: 0.9966, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Step 6240/6250 - Loss: 1.1600, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Step 6240/6250 - Loss: 0.9875, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Step 6240/6250 - Loss: 0.9542, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Step 6240/6250 - Loss: 0.9523, LR: 0.000100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Step 6240/6250 - Loss: 1.0348, LR: 0.000099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Step 6240/6250 - Loss: 0.7826, LR: 0.000099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Step 6240/6250 - Loss: 0.8142, LR: 0.000099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Step 6240/6250 - Loss: 0.7317, LR: 0.000099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Step 6240/6250 - Loss: 0.6582, LR: 0.000099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Step 6240/6250 - Loss: 0.5478, LR: 0.000099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Step 6240/6250 - Loss: 0.4530, LR: 0.000099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Step 6240/6250 - Loss: 0.3743, LR: 0.000099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Step 6240/6250 - Loss: 0.3984, LR: 0.000099"
     ]
    }
   ],
   "source": [
    "\n",
    "vit.train()\n",
    "num_epoch=30\n",
    "optimizer = torch.optim.Adam(params=vit.parameters(),lr = 1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader) * num_epoch)  # full schedule over all steps\n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    torch.save(vit.state_dict(),f'vit_{epoch}.pth')\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to('cuda')\n",
    "        labels = labels.to('cuda')\n",
    "        patches = splitBatch(images)\n",
    "\n",
    "        y = vit(patches)\n",
    "        loss = F.cross_entropy(y, labels) / num_grad_accum\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        if (i + 1) % num_grad_accum == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            \n",
    "            print(f\"\\rEpoch {epoch}, Step {i+1}/{len(train_loader)} - Loss: {total_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.6f}\", end='')\n",
    "            total_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 1.0\n",
      "acc: 1.0\n",
      "acc: 1.0\n",
      "acc: 0.96875\n",
      "acc: 0.975\n",
      "acc: 0.9791666666666666\n",
      "acc: 0.9821428571428571\n",
      "acc: 0.984375\n",
      "acc: 0.9861111111111112\n",
      "acc: 0.9875\n",
      "acc: 0.9886363636363636\n",
      "acc: 0.9895833333333334\n",
      "acc: 0.9807692307692307\n",
      "acc: 0.9821428571428571\n",
      "acc: 0.975\n",
      "acc: 0.96875\n",
      "acc: 0.9705882352941176\n",
      "acc: 0.9652777777777778\n",
      "acc: 0.9671052631578947\n",
      "acc: 0.96875\n",
      "acc: 0.9642857142857143\n",
      "acc: 0.9659090909090909\n",
      "acc: 0.967391304347826\n",
      "acc: 0.9635416666666666\n",
      "acc: 0.955\n",
      "acc: 0.9567307692307693\n",
      "acc: 0.9583333333333334\n",
      "acc: 0.9553571428571429\n",
      "acc: 0.9568965517241379\n",
      "acc: 0.9583333333333334\n",
      "acc: 0.9596774193548387\n",
      "acc: 0.9609375\n",
      "acc: 0.9621212121212122\n",
      "acc: 0.9558823529411765\n",
      "acc: 0.9571428571428572\n",
      "acc: 0.9583333333333334\n",
      "acc: 0.956081081081081\n",
      "acc: 0.9539473684210527\n",
      "acc: 0.9551282051282052\n",
      "acc: 0.95625\n",
      "acc: 0.9542682926829268\n",
      "acc: 0.9494047619047619\n",
      "acc: 0.9476744186046512\n",
      "acc: 0.9488636363636364\n",
      "acc: 0.95\n",
      "acc: 0.9510869565217391\n",
      "acc: 0.9521276595744681\n",
      "acc: 0.953125\n",
      "acc: 0.9489795918367347\n",
      "acc: 0.95\n",
      "acc: 0.9485294117647058\n",
      "acc: 0.9495192307692307\n",
      "acc: 0.9457547169811321\n",
      "acc: 0.9444444444444444\n",
      "acc: 0.9454545454545454\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m         correctly_labeled \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc:\u001b[39m\u001b[38;5;124m\"\u001b[39m,correctly_labeled\u001b[38;5;241m/\u001b[39mtotal_images)\n\u001b[0;32m---> 22\u001b[0m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m, in \u001b[0;36minference\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m patches \u001b[38;5;241m=\u001b[39m splitBatch(images)\n\u001b[1;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m vit(patches)\n\u001b[0;32m---> 16\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(y, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m correctly_labeled \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vit  = VIT(layer_num=8,patch_size=16,channels=3,context_length=256,embedding_dim=768,num_attn_head=8,class_size=10)\n",
    "\n",
    "vit.load_state_dict(torch.load(\"vit_29.pth\"))\n",
    "vit.to('cuda')\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference():\n",
    "    vit.eval()\n",
    "    correctly_labeled = 0\n",
    "    total_images = 0\n",
    "    for images,labels in train_loader:\n",
    "        total_images  += images.shape[0]\n",
    "        images = images.to('cuda')\n",
    "        patches = splitBatch(images)\n",
    "        y = vit(patches)\n",
    "        labels = labels.to('cuda')\n",
    "        preds = torch.argmax(y, dim=1)\n",
    "        correctly_labeled += (preds == labels).sum().item()\n",
    "        print(\"acc:\",correctly_labeled/total_images)\n",
    "inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
